{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33624715",
   "metadata": {},
   "source": [
    "# Praktikum 3: Manipulasi Data Tabular dengan Pandas\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/pakizhan-ump/ml-umpontianak/blob/main/Modules/Week-02/Praktikum-02/Praktikum_3_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## üéØ Tujuan Praktikum\n",
    "Mahasiswa mampu menggunakan library **Pandas** untuk memuat, membersihkan, memanipulasi, dan menganalisis data dalam bentuk tabel (DataFrame).\n",
    "\n",
    "## üìñ Dasar Teori\n",
    "**Pandas** adalah library yang dibangun di atas NumPy, dirancang khusus untuk analisis dan manipulasi data terstruktur atau tabular. Dua struktur data utamanya adalah:\n",
    "* **Series:** Sebuah array satu dimensi yang memiliki label (indeks). Ini bisa dianggap sebagai satu kolom dalam sebuah tabel.\n",
    "* **DataFrame:** Struktur data dua dimensi seperti tabel pada spreadsheet atau database SQL. DataFrame terdiri dari baris dan kolom, di mana setiap kolomnya adalah sebuah Pandas Series.\n",
    "\n",
    "Pandas sangat esensial untuk tahap *data cleaning*, *preprocessing*, dan *exploratory data analysis (EDA)* dalam alur kerja machine learning. Ia menyediakan fungsi-fungsi tingkat tinggi untuk membaca file (CSV, Excel), menangani data yang hilang (*missing values*), melakukan pengelompokan (*grouping*), dan seleksi data yang kompleks dengan mudah.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0eba88",
   "metadata": {},
   "source": [
    "# üîß OPERASI FUNDAMENTAL PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5da1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd1ba99",
   "metadata": {},
   "source": [
    "# 1. DATAFRAME CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca9162",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DATAFRAME CREATION ===\")\n",
    "# From dictionary\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 30, 35, 28],\n",
    "    'Salary': [50000, 60000, 70000, 55000],\n",
    "    'Department': ['IT', 'HR', 'IT', 'Finance']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f60d0c",
   "metadata": {},
   "source": [
    "# 2. ACCESS & INDEXING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2945f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== ACCESS & INDEXING ===\")\n",
    "print(\"Column 'Name':\", df['Name'].tolist())\n",
    "print(\"First row:\\n\", df.iloc[0])                    # By integer position\n",
    "print(\"Rows 1-2:\\n\", df.iloc[1:3])\n",
    "print(\"Filter Age > 28:\\n\", df[df['Age'] > 28])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e5c93d",
   "metadata": {},
   "source": [
    "# 3. ADD/REMOVE COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8694ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n=== ADD/REMOVE COLUMNS ===\")\n",
    "df['Experience'] = [2, 5, 8, 3]                     # Add new column\n",
    "df['Senior'] = df['Age'] > 30                       # Conditional column\n",
    "df = df.drop('Experience', axis=1)                  # Remove column\n",
    "print(\"After modifications:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a0989",
   "metadata": {},
   "source": [
    "# 4. HANDLING MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f038a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "df_with_na = df.copy()\n",
    "df_with_na.loc[1, 'Salary'] = np.nan\n",
    "df_with_na.loc[2, 'Age'] = np.nan\n",
    "\n",
    "print(\"With missing values:\\n\", df_with_na)\n",
    "print(\"Is null:\\n\", df_with_na.isnull())\n",
    "print(\"Fill with mean:\\n\", df_with_na.fillna(df_with_na.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8169ad",
   "metadata": {},
   "source": [
    "# 5. GROUPING & AGGREGATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== GROUPING & AGGREGATION ===\")\n",
    "grouped = df.groupby('Department')\n",
    "print(\"Grouped means:\\n\", grouped.mean())\n",
    "print(\"Grouped description:\\n\", grouped['Salary'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a193eb",
   "metadata": {},
   "source": [
    "# 6. SORTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4eb266",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== SORTING ===\")\n",
    "df_sorted = df.sort_values('Salary', ascending=False)\n",
    "print(\"Sorted by Salary:\\n\", df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa190db",
   "metadata": {},
   "source": [
    "# 7. MERGING & JOINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c580c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== MERGING ===\")\n",
    "df2 = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Eve'],\n",
    "    'Bonus': [5000, 3000, 4000]\n",
    "})\n",
    "merged = pd.merge(df, df2, on='Name', how='left')\n",
    "print(\"Merged DataFrame:\\n\", merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef532c",
   "metadata": {},
   "source": [
    "# 8. PIVOT TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a0ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== PIVOT TABLES ===\")\n",
    "pivot = df.pivot_table(values='Salary', index='Department', aggfunc=['mean', 'count'])\n",
    "print(\"Pivot table:\\n\", pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d90015c",
   "metadata": {},
   "source": [
    "# 9. DATETIME OPERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bffb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n=== DATETIME OPERATIONS ===\")\n",
    "dates = pd.date_range('20230101', periods=4)\n",
    "df_dates = df.copy()\n",
    "df_dates['Join_Date'] = dates\n",
    "df_dates['Year'] = df_dates['Join_Date'].dt.year\n",
    "print(\"With dates:\\n\", df_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918c0958",
   "metadata": {},
   "source": [
    "# 10. STRING OPERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777149d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== STRING OPERATIONS ===\")\n",
    "df['Name_Upper'] = df['Name'].str.upper()\n",
    "df['Name_Length'] = df['Name'].str.len()\n",
    "print(\"String operations:\\n\", df[['Name', 'Name_Upper', 'Name_Length']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb8792f",
   "metadata": {},
   "source": [
    "# üèãÔ∏è LATIHAN 3: OPERASI PANDAS UNTUK DATA ANALYSIS\n",
    "### EXPLORATORY DATA ANALYSIS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac1c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TODO: Analisis Dataset Retail'''\n",
    "# Create sample retail dataset\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2023-01-01', '2023-03-31', freq='D')\n",
    "retail_data = pd.DataFrame({\n",
    "    'date': np.random.choice(dates, 1000),\n",
    "    'product_id': np.random.randint(1, 11, 1000),\n",
    "    'quantity': np.random.randint(1, 10, 1000),\n",
    "    'price': np.random.uniform(10, 100, 1000),\n",
    "    'customer_id': np.random.randint(1, 101, 1000)\n",
    "})\n",
    "retail_data['revenue'] = retail_data['quantity'] * retail_data['price']\n",
    "\n",
    "# TODO 1: Hitung total revenue per product\n",
    "revenue_per_product = # TODO\n",
    "\n",
    "# TODO 2: Temukan top 5 customers berdasarkan total spending\n",
    "top_customers = # TODO\n",
    "\n",
    "# TODO 3: Analisis time series - revenue per hari\n",
    "daily_revenue = # TODO\n",
    "\n",
    "# TODO 4: Buat fungsi untuk detect anomalies dalam quantity\n",
    "def detect_quantity_anomalies(df, threshold=2):\n",
    "    # TODO: Detect anomalies using Z-score\n",
    "    pass\n",
    "\n",
    "anomalies = detect_quantity_anomalies(retail_data)\n",
    "\n",
    "assert len(revenue_per_product) <= 10, \"Should have max 10 products\"\n",
    "assert len(top_customers) == 5, \"Should have top 5 customers\"\n",
    "print(\"‚úÖ Pandas operations completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
